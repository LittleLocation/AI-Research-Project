# README: Analyzing AI-Generated Propaganda

## Objective

The objective of this project is to evaluate the ability of college students to distinguish between AI-generated propaganda and authentic news content. By assessing their discernment skills, this study aims to shed light on the risks posed by AI-driven disinformation and the current state of media literacy among younger demographics.

## Background

The rapid proliferation of artificial intelligence in communication has enabled the creation of human-like content, raising concerns about its misuse in generating propaganda. This project investigates the intersection of AI technology, media influence, and public perception. By focusing on AI-generated propaganda, the research explores how effectively students can identify disinformation and the factors influencing their decisions.

Key technologies such as ChatGPT, developed by OpenAI, play a significant role in this study. ChatGPT uses advanced transformer-based neural networks and reinforcement learning from human feedback to generate human-like responses, making it both a valuable tool and a potential risk in the dissemination of persuasive disinformation.

## Methodology

### Study Design
Participants reviewed a series of 12 headlines—six AI-generated and six authentic—on topics including the Great Depression and the 2020 French presidential election. They were tasked with identifying the origin of each headline and rating their confidence on a scale from 1 (least confident) to 5 (most confident). Data was collected via surveys, providing insights into accuracy rates and confidence levels.








 
